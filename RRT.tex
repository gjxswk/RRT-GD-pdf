%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\usepackage{graphicx}
\usepackage{epsfig} % less modern
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{subfigure}
\usepackage{graphicx,epstopdf}
\def\degree{${}^{\circ}$}
	
\title{\LARGE \bf
RRT-GD: An Efficient Rapidly-exploring Random Tree Approach with Goal Directionality for Redundant Manipulator Path Planning
}


\author{Junxiang Ge$^{1}$, Fuchun Sun$^{1}$, Chunfang Liu$^{1}$% <-this % stops a space
%\thanks{*This work was not supported by any organization}% <-this % stops a space
\thanks{$^{1}$State Key Lab of Intelligent Technology and Systems, Tsinghua National Laboratory for Information Science and Technology (TNList), Department of Computer Science and Technology, Tsinghua University. {\tt\small gejx14@mails.tsinghua.edu.cn, fcsun@tsinghua.edu.cn, cfliu1985@gmail.com}}%
}

\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Rapidly-exploring random trees (RRT) method performs well for obstacle-avoiding motion planning. However, it is not fast enough and less goal-direction. In this paper, we propose an effective rapidly-exploring random trees method with goal directionality (RRT-GD)  for redundant manipulator path planning. The presented RRT-GD model concentrates both on the status of the end actuator and on the movements of the joints that the Newton-Raphson method is employed for inverse kinematics. In order to speed up the path planning, the path searching algorithm is modified to be goal-directionality and the quintic polynomial is applied to smooth the planned path. In the experiments, it shows that RRT-GD tends to be 10 or more times faster than the usual RRT algorithm when doing the same obstacle-avoiding path planning task. Therefore, RRT-GD could be more efficient and useful in doing our daily works.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
 Rapidly-exploring random trees (RRT) method was proposed by SM Lavalle and JJ Kuffner [1], which is a suitable way to be used in obstacle-avoiding path planning for mobile robot or multiple freedom manipulator. It constructs a graph with obstacle free points in feasible space based on random sampling, in which the optimal path is searched from the initial point to the goal point. There are also many other intelligent path planning methods [9-11]. Compared with them, RRT method attends to explore unknown space so that the graph constructed by RRT will gradually fill up the feasible space as long as the exploring times is enough. Besides, RRT method don't need precise modeling of the obstacles, instead, it only needs the information if or not a point is obstacle free through doing collision detect, thus ending up with the high efficiency of obstacle-free path planning.

Though it has the above advantages, RRT method will still perform low success rate of planning when there is many obstacles surrounded, or the free space is too large to explore. For these problems, JJ Kuffner and SM Lavalle [2, 3] proposed a bi-directional RRT algorithm (bi-RRT) that two trees were built based on the initial point and the goal point separately. When expanding each time, the tree of initial point will extend to the goal-point based tree, or the contrary way, until these two trees meets. Because of goal heuristic, this approach improves the success rate of path planning. In spite of this modification, we still find it defective sometimes for path planning.

As mentioned before, RRT attends to explore the whole space. However, for goal-reaching works, it doesn't need to explore the whole space in the most time. What we need to do is to find a feasible way from the initial point to the goal point without obstacle collision, i.e., only a part of the whole space is necessary for exploration. Thus, in this paper, we propose a modified RRT method with goal directionality (RRT-GD) for path planning with goal-directionality exploration. The experiments demonstrate that the proposed method could quickly accomplish the obstacle avoiding path planning and the planning speed is 10 times faster than that of the original RRT method.

On the other hand, for performing the redundant manipulator motion, it is necessary to transform each point in the path tree from the configuration space (C-space) to robots' joint space by using the inverse kinematics optimization. There are lots of methods to do inverse kinematics optimization for redundant manipulator, e.g., MLG (most likeyly gradient method) [4, 5], WLN (weighted least norm method) [6], Genetic Algorithm [7], GP (gradient projection method), etc. In this paper, Newton-Raphson method is adopted to perform the inverse kinematics optimization work. In order to make comparation, we also implement MLG method in our exprements according to [4, 5]. Compared to other methods, Newton-Raphson method has faster converging speed and more accurate result that it takes less than 10 iteration times (usually 5 or 6 times) and has deviations less than 1 micrometers. Finally, the quintic polynomial approach [8] is utilized to smooth the planned path.

\section{RRT with Extended Steps}

In this section, the original RRT method for obstacle-avoiding path planning is introduced firstly. Then, we show the presented RRT-GD approach for faster motion planning with goal directionality.

\subsection{Rapidly-exploring Random Trees}

The basic problem of RRT is how could we move the manipulator from the initial status to the goal status without collision with the obstacles in the space. To make it more clearly, we make appointments on the following mathematical symbols to express status space (S-space) and configuration space (C-space).

We use $n$ to stand for the degree of freedom (DOF) of the robot manipulator, which is 7 in our exprement. So S-space is expressed with 7 parameters from $q_1$ to $q_7$, with the expression like (\ref{eq_status}):

\begin{equation}
\label{eq_status}
S \ = \ (q_{1}, q_{2}, \ ...  \ , q_{7})
\end{equation}

As for the C-space, i.e., pose space, we use Euler angles that obeys Euler Z-X-Z transformation rules to express the azimuth angles, which displays like $\gamma = (\psi, \theta, \phi)$. Position writes like $P=(x,y,z)$. Get the position and Euler angles together, we define $m$ as the dimension of pose, which is 6 in this way, and the expression of pose is expressed like (\ref{eq_configuration}):

\begin{equation}
\label{eq_configuration}
X = (P,\gamma) = (x,y,z,\psi,\theta,\phi)
\end{equation}

Note that $n > m$ should be guatanteed since it is a redundant system. Therefore, we get the initial condition of collsion-free path planning problem as this: knowing the initial joints' angle $S_{0}\in \mathbb{R}^n$, the initial status of the end-effector $X_{0}\in \mathbb{R}^m$ (which could be computed from $S_{0}$), and the goal status of the end-effector $X_{g}\in \mathbb{R}^m$. The relevant notations and functions of RRT are illustrated as below:

\begin{itemize}

\item $A_{0}$: the whole pose space which can be reached by robot manipulator in C-space. 

\item $A_{free}$: free space belong to $A_{0}$, i.e., $A_{free} \in A_{0}$, and there is no obstacle in $A_{free}$.

\item $A_{obs}$: space of obstacle, i.e., $A_{obs} = A_{0}  \backslash A_{free}$.

\end{itemize}

Actually, it is difficult to build the accurate boundary of $A_{0}$. In convenience, we use $X_{min}$ and $X_{max}$ as the two terminal vertex of $A_{0}$ here.

\begin{equation}
A_{0} = \{X|\ X_{min} < X < X_{max}\}.
\label{eq_a0}
\end{equation}

RRT method builds a path tree $T = (V, E)$, with the initial point $X_{0}$ for pose and $S_{0}$ for status as the first tree point, while $V$ stands for all points and $E$ is the relation between these points. The basic functions that RRT method use are defined as follow:

\begin{itemize}

\item \textit{sample}:  generate a random point $X_{ram}$ in pose format within $A_{free}$.

\item \textit{distance}:  compute the distance between two points in $A_{0}$ by using (\ref{eq_rrtDistance}).

\item \textit{nearest\_neighbor}: given the point X, this function returns the nearest point $X_{near}$ to X in $T$.

\item \textit{steer}: given the random point $X_{ram}$ and $X_{near}$, this function returns a new point $X_{new}$ in $A_{free}$, which is nearer to $X_{ram}$ than $X_{near}$.

\item \textit{collisionTest}: given point $X$, return 1 for obstacle free and 0 for obstacle collision.

\end{itemize}

Then, the basic algorithm of RRT is displayed as the pseudocode in Fig. \ref{fig_rrt}.

\begin{figure}[thpb]
      \centering
      \framebox{
      \parbox{3in}
      {\scriptsize
      $
      RRT (S_{0}, A_{0})\\
      1.\ V \leftarrow \{S_{0}\}; E \leftarrow \o; i \leftarrow 0;\\
      2.\ while\ i < N\ do \\
      3.\ \{ \\
      4.\qquad T \leftarrow (V,\ E); \\
      5.\qquad X_{rand} \leftarrow sample(i); i \leftarrow i+1; \\
      6.\qquad T \leftarrow extend(T, X_{rand});\\
      7.\ \} \\
      $
      \\
      $
      extend(T, X_{rand}) \\
      1.\ X_{near}=  nearest\_neighbor(T, X_{rand});\\
      2.\ X_{new} = steer(X_{near}, X_{rand});\\
      3.\ if\ X_{new}\ and\ collisionTest(X_{new})\\\
      4.\qquad V \leftarrow V \cup \{X_{new}\};\\
      5.\qquad E \leftarrow E \cup \{(X_{near}, X_{new})\};\\
      5.\qquad return\ success;\\
      6.\ else\\
      7.\qquad return\ fail;
      $
	 }
}
      \caption{The pseudocode of RRT algorithm.}
      \label{fig_rrt}
\end{figure}

In our algorithm, an `rrtDistance' method is employed for calculating the distance between points, show as (\ref{eq_rrtDistance}). It is made to concentrate more on the accuracy of position than the accuracy of Euler azimuth angles.

 \begin{equation}
 \begin{array}{ll}
 &rrtDistance(X_{1},X_{2})=\alpha ||P_{1}-P_{2}|| + \\
& \qquad\qquad (1-\alpha) ||\gamma_{1}-\gamma_{2}||, \ 0 < \alpha < 1.
 \end{array}
 \label{eq_rrtDistance}
 \end{equation}

 In our exprements, we choose $\alpha > 0.5$, e.g., $\alpha = 0.8$. The \textit{sample} function generates a point $A_{0}$ that $X_{min} < A_{0} < X_{max}$. Then, the random point $X_{ram}$ is produced with the \textit{sample} function as shown in  (\ref{eq_sample}).

 \begin{equation}
 X_{ram} = X_{min} + t \times (X_{max}-X_{min}), 0<t<1;
  \label{eq_sample}
 \end{equation}

Notice that $t$ is randomly generated in the interval (0, 1) and the \textit{sample} function would produce all the points of $A_{0}$. As for the \textit{steer} function, a new point will be generated depending on $X_{near}$ and $X_{ram}$ as shown in (\ref{eq_ram}):

\begin{equation} \label{eq_ram}
 \begin{array}{rr}
 X_{new} = X_{near} + s(X_{ram}-X_{near})/||X_{ram}-&\\
 X_{near}||,\ 0<s<||X_{ram}-X_{near}||.&
 \end{array}
 \end{equation}

 We called $s$ in (\ref{eq_ram}) the step-length. In RRT algorithm, each time when \textit{steer} function runs, the RRT tree $T$ will attend $s$ length forward. Since $X_{rand}$ will be anywhere in $A_{0}$, it is inferred that the direction tree $T$ extends to is all-dimension. These properties of RRT method will be discussed in the next subsection.

\subsection{Modified RRT Approach}

Though RRT can explore the whole space $A_{0}$ to get an obstacle-free path to reach the goal point, it still has some shortage when it actually runs. Since RRT extends only one step (with step-length $s$) further each time, it seems slow sometimes when $A_{0}$ is large enough to explore. On the other hand, RRT tree is built beginning with the initial point, leaving out the goal point in the tree-built process. Still, there are other insufficients with RRT, which results in many modified RRT methods. Bi-RRT [2, 3] is one of them. Here, we briefly introduce this modified model.

Bi-RRT extends more steps until the new point generated  is in collision with obstacles or reach the random point $X_{ram}$. And bi-RRT maintains two trees in its memory, one starting extend function from the initial point and the other from the goal point. The two trees extend to each other interchangeably every time until they meet in the space, which is the reason the name `bi-RRT' comes from. With such modification, bi-RRT takes in account of both the initial point and the goal point together with a faster extending speed. Nevertheless, it still hasn't solved the problem of exploring unuseful space since the two trees will both explore the whole space.

In our model, multiple steps extending strategy is integrated into our algorithm. The multi-extend algorithm is written as Fig. \ref{fig_multiExtend}:

\begin{figure}[thpb]
      \centering
      \framebox{
      \parbox{3in}
      {\scriptsize
      $
      multi\_extend(T, X_{rand})\\
      1.\ [X_{new}, result] = extend(T, X_{rand});\\
      2.\ if\ result = fail\ or\ collisionTest(X_{new}) = 0\\
      3.\qquad return\ fail;\\
      4.\ while\ result = success \\
      5.\ \{ \\
      6.\qquad [X_{new}, result] = extend(X_{new}, X_{rand});\\
      \begin{aligned}
      7.\qquad if\ collision&Test(X_{new}) = 0\ or\ \\ &surpass(X_{new}, X_{rand})\\
      \end{aligned} \\
      8.\qquad \qquad break; \\
      9.\ \} \\
      10.\ return\ success.
      $
	 }
}
      \caption{Multi-step extended pseudocode}
      \label{fig_multiExtend}
\end{figure}

The function `$surpass(X_{new},X_{rand})$' detects if $X_{new}$ is near enough to $X_{rand}$. If the two points are close enough, then `true' returns and `multi\_extend' method will be stopped; otherwise, the `false' returns and the extending process continues. It could be deduced that, if the extending direction is correct, i.e., closer to the goal point, we could reach the goal point faster; else, this extending strategy will then take more time than one-step extending strategy. We solve this problem by presenting RRT-GD (RRT with goal-directionality) model. 

\subsection{RRT-GD: Trun RRT to be goal-directionality}

As mentioned before, both RRT and its modified methods (includeing bi-RRT) are easy to explore unuseful space which do not need in the daily tasks, i.e., it lacks goal-directionality. In order to solve this problem, taking the normal task in our experiment circumstance into account, we turn our sights to the `sample' function in RRT. Simple to find that if we just don't use a whole space `sample' method, but limit it to a useful space, we can decide the extending direction of RRT tree $T$, that is the kernel principle within our modified RRT method called RRT-GD.

Originally, `sample' method is random in the whole work space, thus its extending direction is all-around. The sketch map can be seen in Fig. \ref{fig_sketch}. When we use a space containing the goal point $X_{g}$, called sample space $A_{sam}$, which can simply be a sphere with $X_{g}$ centering (of course other shapes also works, e.g., cuboid), the extending direction can be limit to goal-direction, as Fig. \ref{fig_sketch} shows. There exists another case: if the initial point is contained in sample space, i.e., $X_{0}\in A_{sam}$, then the extending direction could also be all-around just as usual RRT does, but since the probability of the goal-directions becomes larger than the other directions, the principle of RRT-GD could also work.

\begin{figure}[thpb]
      \centering
      \framebox{
      \parbox{3in}{
      \subfigure[Extend direction of RRT: all-direction.]
      {
      \label{subfig1_sketch}
      \includegraphics[width=7cm, height=3cm]{extendRRT.eps}	
      }
      \subfigure[Extend direction of RRT-GD: goal-direction.]
      {
      \label{subfig2_sketch}
      \includegraphics[width=7cm, height=3cm]			   {extendRRTGD.eps}	
      }
      }
      }
      \caption{Extend direction of RRT and RRT-GD. Pink cuboid is for the whole working space. Blue sphere is for sample space. }
      \label{fig_sketch}
\end{figure}

With this change, RRT-GD needs less extending times and the tree it builds will go to the goal point rapidly. But on the other hand, it could also be easily seen that RRT-GD can't get answer if all the extending direction of it can't be explored further, e.g., a big obstacle object stands between the initial point and the goal point so that it resist all the extending directions RRT-GD could generate. That is truly a problem in theory, but RRT-GD could work well in fact because of the following reasons:

\begin{itemize}

\item In fact, we could not get the accurate profile of the whole space $A_{0}$ and $A_{ram}$ most of the time, so the method of choosing a big range of $A_{0}$ to satisfied our tasks itself is in RRT-GD method, i.e., RRT-GD is the same with RRT when we take the whole working space $A_{0}$ as sample space.
\item  As mentioned above, RRT-GD could also be all-direction if the sample space $A_{sam}$ include $X_{0}$. So RRT-GD could get the correct answer as RRT could.
\item In fact, there will not be so many obstacles, and each obstacle will not be so big in the working space for our daily tasks. As long as we make $A_{sam}$ large enough, RRT-GD could always works correctly.  

\end{itemize} 

As we can see later in our exprements, RRT-GD could work faster and better than RRT almost all the time.

\section{Inverse Kinematics with Newton-Raphson method}

Let's look on the inverse kinematics problem: we know $S_{0}$ (and so $X_{0}$ can be computed) and $X_{g}$, how could we compute $S_{g}$? Newton-Raphson method is an iteration approach that each time it just goes straight from the current point to the goal point with the iteration in (\ref{eq_NR}).

\begin{equation}\label{eq_NR}
S_{n+1} = S_{n} + J^{+} \times minus(X_{g}, X_{n}).
\end{equation}

The current status and pose are written as $S_{n}$ and $X_{n}$, and $J^{+}$ is the generalized inverse transformation of current Jacobian matrix. Then when $X_{n}$ is close enough to $X_{g}$, we get the answer $S_{n+1}$ as result $S_{g}$. Note that though the function name called `minus', it didn't just do simple minus operation as `$X_{g} - X_{n}$', because the Euler azimuth doesn't supplement the minus operation. We should use the Rotate-By-1-Axis method to get the corret answer, since the combination of any fix-axis rotations of rigid body can be seen as one-time fix-axis rotation.

After this work, we write down the Newton-Raphson method as Fig. \ref{fig_newton}.

\begin{figure}[thpb]
      \centering
      \framebox{
      \parbox{3in}
      {\scriptsize
      $
      Newton\_Raphson(S_{0}, X_{g})\\
      1.\ compute\ X_{0}\ and\ J^{+}; i = 0; times = 0;\\
      2.\ while\ \epsilon < rrtDistance(X_{i}, X_{g})\ and\ times < N\\
      3.\ \{ \\
      4.\qquad S_{i+1} = S_{i} + J^{+}\times minus(X_{g}, X_{i});\\
      5.\qquad i = i + 1;times = times + 1;\\
      6.\qquad compute\ X_{i}\ and\ J^{+};\\
      7.\ \}
      $
	 }
}
      \caption{Newton-Raphson method pseudocode}
      \label{fig_newton}
\end{figure}

Here we use N (we set it to 10 in program) to limit the iteration times, for the fact that Newton-Raphson method would always get the correct answer in less than 10 iteration times with accuracy of micrometer, otherwise it would fail with bias greater than $\epsilon$ (1 micrometer), i.e., more iteration times have no use cause it can't improve the accuracy further more.

The quintic polynomial has been used in our program to do path smoothing, the principle of which can be seen in [8]. Supposed we know $S_{0}$, $S_{g}$, we need to plan the medium path in 1 second (of course it can be changed by timing a factor). Then in quintic polynomial method, we plan the path as in (\ref{eq_quintic}):

\begin{equation}
\begin{array}{c}
S(t) = a_{5}t^5+a_{4}t^4+a_{3}t^3+a_{2}t^2+a_{1}t+a_{0};\\
with:
\left \{
\begin{array}{ll}
a_{5} = &6(S_{g}-S_{0});\\
a_{4} = &-15(S_{g}-S_{0});\\
a_{3} = &10(S_{g}-S_{0});\\
a_{2} = &0;\\
a_{1} = &0;\\
a_{0} = &S_{0};\\
\end{array}
\right.
\end{array}
\label{eq_quintic}
\end{equation}

\section{Experiments}

\subsection{Experiment Environment}

We use a 7-DOF (degree of freedom) robot manipulator, show in Fig. \ref{robotGraph} to test the results in our experiment. Then we use the D-H method (Denavit and Hartenberg method) to model our robot arm, with the model axis built obeying D-H parameter method as the Fig. \ref{robotAxisGraph} shows.

   \begin{figure}[thpb]
      \centering
      %\framebox{
      %\parbox{2in}{
      \includegraphics{robotArm.eps}%}
      %}
      \caption{7-DOF robot arm}
      \label{robotGraph}
   \end{figure}

   \begin{figure}[thpb]
      \centering
      \framebox{
      \parbox{1.2in}{
      \includegraphics[height=4cm]{robotaxis.eps}}
      }
      \caption{Robot axis coordinates, obeying D-H parameter method. Numbers in the graph is in milimeter.}
      \label{robotAxisGraph}
   \end{figure}

As a result of this axis coordinates, we get the DH parameters  (show in Table \ref{table1}) from it, which is the key data used in our procedure.

\begin{table}[h]
\caption{$DH\ Parameters\ of\ robot.\ (\theta: joint\ angle;\ d: connecting\ rod\ skew;\ a: connecting\ rod;\ \alpha: tortuosity\ angle\ of\ connecting\ rod.)$}
\label{table1}
\begin{center}
\begin{tabular}{c|ccccc}
\hline
Joint Number & $\theta_i$ & $d_i$(mm) & $a_i$(mm) & ${\alpha_i}$(\degree) & area of $\theta_i$(\degree) \\
\hline
1 & $q_1$ & 300 & 0 & -90 & -180$\sim$180\\
2 & $q_2$ & 0 & 0 & 90 & -90$\sim$90 \\
3 & $q_3$ & 328 & 0 & -90 & -180$\sim$180\\
4 & $q_4$ & 0 & 0 & 90 & -120$\sim$120\\
5 & $q_5$ & 277 & 0 & -90 & -180$\sim$180\\
6 & $q_6$ & 0 & 0 & 90 & -120$\sim$120\\
7 & $q_7$ & 310 & 0 & 0 & -180$\sim$180\\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Comparation between Newton-Raphson and MLG}

MLG (most likely gradient) method is also a iteration method, using the gradient of current point as the iteration direction, the detail of which can be seen in [4, 5]. We implement it and then make comparation between MLG and Newton-Raphson method.

\begin{table*}[h]
\caption{$Comparation\ between\ RRT\ and\ $ Newton-Raphson $ method.\ S_{0} = [0.7854;0.5236;0;0.5236;0;0.5236;0](rad);\ X_{0}=[0.5045;0.5045;0.7223;2.3562;1.5708;-1.5708];\ dist = rrtDistance(X_{0}, X_{g}), all\ their\ units\ are\ meters(m). `\surd'\ means\ successful.\ `\times'\ means\ result\ failed,\ i.e.,\ bias\ (accuracy)\ comes\ out\ more\ than\ 0.1m.$}
\label{table_newton}
\begin{center}
\begin{tabular}{c|c|c|c|c|c|c}
\hline
No. & task(m) & Method & iteration times & time spent($10^{-3}s$) & accuracy(m) & result \\
\hline
\multirow{4}{*}{1}  &
\multirow{4}{*}{
$
\begin{array}{l}
X_{g} =
\left[
\begin{array}{c}
0.50;
0.45;
0.72;
2.35;
1.57;
-1.57
\end{array}
\right] \\ \\
dist = 0.045.
\end{array}
$}
  & N-R & 5 & $6.15$ & $1.28\times 10^{-9}$ & $\surd$ \\
\cline{3-7}
  &    &         & 5 & $5.70$ & $6.50\times10^{-3}$ & $\surd$ \\ \cline{4-7}
   &    & MLG & 10 & $6.52$ & $2.64\times10^{-3}$ & $\surd$ \\ \cline{4-7}
   &    &         & 20 & $11.76$ & $1.25\times10^{-3}$ & $\surd$ \\
\hline
\multirow{4}{*}{2} &
\multirow{4}{*}{
$
\begin{array}{l}
X_{g} =
\left[
\begin{array}{c}
0.5;
0.48;
0.72;
2.35;
1.55;
-1.55
\end{array}
\right] \\ \\
dist = 0.025.
\end{array}
$
}
& N-R & 4 & 2.38 & $2.34\times10^{-7}$ & $\surd$ \\
\cline{3-7}
 &     &         & 5 & 3.95 & $9.74\times10^{-2}$ & $\surd$\\
\cline{4-7}
 &     &  MLG &10& 6.60 & $9.56\times10^{-2}$ & $\surd$\\
 \cline{4-7}
 &     &         &20& 12.77& $9.39\times10^{-2}$ & $\surd$\\
\hline
\multirow{4}{*}{3}
&
\multirow{4}{*}{
$
\begin{array}{l}
X_{g} =
\left[
\begin{array}{c}
0.44;
0.44;
0.68;
2.30;
1.57;
-1.57
\end{array}
\right] \\ \\
dist = 0.092.
\end{array}
$
}
& N-R & 7 &3.87 & $5.87\times10^{-8}$ & $\surd$ \\
\cline{3-7}
 &    &        & 5 & 3.94 & $1.65\times10^{-2}$ & $\surd$ \\
\cline{4-7}
 &    & MLG &10& 6.64 & $1.73\times10^{-2}$ & $\surd$ \\
 \cline{4-7}
 &    &         &20& 12.20& $1.78\times10^{-2}$ & $\surd$ \\
 \hline
\multirow{4}{*}{4}
&
\multirow{4}{*}{
$
\begin{array}{l}
X_{g} =
\left[
\begin{array}{c}
0.45;
0.55;
0.60;
2.00;
1.57;
-1.57
\end{array}
\right] \\ \\
dist = 0.184.
\end{array}
$
}
& N-R & 9 &5.70 & $5.53\times10^{-10}$ & $\surd$ \\
\cline{3-7}
 &    &        & 5 & 4.46 & $1.37\times10^{-1}$ & $\times$ \\
\cline{4-7}
 &    &  MLG &10& 7.31 & $1.22\times10^{-1}$ & $\times$ \\
 \cline{4-7}
 &    &         &20& 11.65& $1.12\times10^{-1}$ & $\times$ \\
 \hline
\end{tabular}
\end{center}
\end{table*}

Four groups of experiments has been done within this comparation. These tests start with the same initial point $q_0$, and so the same with $X_0$, and go to different goal point appointed by $X_{g}$. Note that the iteration times of MLG method is an input variable,  so we take 5, 10, and 20 iteration times here as representatives. As Table \ref{table_newton} shows, in these groups of exprements, we make sense that:

\begin{itemize}

\item  The time spent by Newton-Rapshon method is in the same order of magnitude with 5-iteration-times MLG method.
\item  Newton-Raphson method usually ends up with bias no more than $10^{-6}m$, while MLG with deviation error higher than $10^{-3}m$.
\item Newton-Raphson is suitified to more tasks when doing inverse kinematics, which can be proved in group 4, with Newton-Raphson method successful and MLG failed.
\item When Newton-Raphson method fails in doing inverse kinematics, MLG method may always can't work well, because they both use the gradient of current point. 

\end{itemize}

Minded that whether the result fail or success doesn't depend on `dist' parameter, it is decided by many reasons. Sometimes a small `dist' even like $0.02m$ may also result in failed both for Newton-Raphson method and MLG method.

\subsection{Comparation between RRT-GD and RRT}

We implement our `sample' method with sample space in sphere shape of radius set to $0.5m$ for RRT-GD. We can see the comparation between RRT and RRT-GD in TABLE \ref{table_RRTGD}.

\begin{table*}[h]
\caption{$Comparation\ between\ $RRT$\ and\ $RRT-GD$\ method.\ S_{0} = [-0.2618;-0.2618;0;-1.3090;0;-1.3962;0](rad);\ X_{0}=[0.4011;0.1075;0.3115;-1.8326;2.9671;1.5708];\ dist = rrtDistance(X_{0}, X_{g}), all\ their\ units\ are\ meters(m). `\times'\ means\ result\ failed.$}
\label{table_RRTGD}
\begin{center}
\begin{tabular}{c|c|c|c|c|c}
\hline
No. & task(m) & Method & successful extending times & failed extending times &time spent($s$) \\
\hline
\multirow{2}{*}{1}  &
\multirow{2}{*}{
$
\begin{array}{l}
X_{g} =
\left[
\begin{array}{c}
0.42;
-0.22;
0.22;
-1.83;
2.97;
-1.57
\end{array}
\right] \\
dist = 0.7108.
\end{array}
$}
  & RRT & 426 & 3006 & 32.74 \\
\cline{3-6}
  &    &  RRT-GD & 9 & 27 & 0.44 \\
\hline
\multirow{2}{*}{2} &
\multirow{2}{*}{
$
\begin{array}{l}
X_{g} =
\left[
\begin{array}{c}
0.42;
0.22;
0.22;
-1.83;
2.80;
-1.50
\end{array}
\right] \\
dist = 0.6668.
\end{array}
$
}
& RRT & 506 & 4250 & 47.39 \\
\cline{3-6}
 &     &  RRT-GD & 3 & 1 & 0.16 \\
\hline
\multirow{2}{*}{3}
&
\multirow{2}{*}{
$
\begin{array}{l}
X_{g} =
\left[
\begin{array}{c}
0.32;
0.02;
0.20;
-1.80;
2.80;
-1.57
\end{array}
\right] \\
dist = 0.5858;
\end{array}
$
}
& RRT & 221 &  1181 & 12.66 \\
\cline{3-6}
 &    & RRT-GD & 3 & 12 & 0.220 \\
 \hline
 \multirow{2}{*}{4}
&
\multirow{2}{*}{
$
\begin{array}{l}
X_{g} =
\left[
\begin{array}{c}
0.51;
0.12;
0.22;
-1.73;
2.90;
-1.57
\end{array}
\right] \\
dist = 0.7326;
\end{array}
$
}
& RRT & \multicolumn{3}{c}{$\times$} \\
\cline{3-6}
 &    & RRT-GD & 4 & 6 & 0.219 \\
 \hline
\end{tabular}
\end{center}
\end{table*}

\begin{figure*}[thpb]
      %\centering
      \framebox{
      \parbox{6.6in}{
      \centerline{
      \subfigure[RRT in Group No.1 of Table \ref{table_RRTGD}]
      {
      \label{Subfig.1}
      \includegraphics[width=2.5in]{RRT1.eps}	
      }
      \hfil
      \subfigure[RRT-GD in Group No.1 of Table \ref{table_RRTGD}]
      {
      \label{Subfig.2}
      \includegraphics[width=2.5in]{RRTGD1.eps}	
      }
      }
      \hfil
      %\framebox{
      %\parbox{7in}{
      \subfigure[RRT in Group No.2 of Table \ref{table_RRTGD}]
      {
      \label{Subfig.3}
      \includegraphics[width=2.5in]{RRT2.eps}
      }
      \hfil
      \subfigure[RRT-GD in Group No.1 of Table \ref{table_RRTGD}]
      {
      \label{Subfig.4}
      \includegraphics[width=2.5in]{RRTGD2.eps}	
      }
      }
      }
      \caption{Result comparation between RRT and RRT-GD. The blue sphere is the sample space we use with goal point centering in red. The range of pink cuboid is our whole work space. The yellow sphere or cuboid is obstacle. The crayon line is the planned path starting from initial point to goal point. }
      \label{fig_final}
\end{figure*}

We take the same initial point as $S_{0}$ in TABLE \ref{table_RRTGD}, and let the end manipulator go to different goal points. The total execution times for `extend' method, on which time is mainly spent on, is the sum of `successful extending times' and `failed extending times' in Table \ref{table_RRTGD}. One point which should be reminded is that the data in a group in TABLE \ref{table_RRTGD} is the best result within 10 tests (each group takes 10 tests). The corresponding planned path of group 1 and 2 in TABLE \ref{table_RRTGD} is show in Fig. \ref{fig_final}. From Table \ref{table_RRTGD} and Fig. \ref{fig_final}, we can learn that:

\begin{itemize}

\item RRT-GD uses much less time and iteration times compared to RRT when doing the same work. As we can see, RRT-GD attends to be 10 times faster or more, speeding up the algorithm remarkably.
\item RRT-GD can perform the path planning real-timely in these tasks, with planning time less than 0.5$s$, which is a great superior comparing to the traditional RRT method.
\item RRT-GD can do the task that RRT can't, as in task 4 of Table \ref{table_RRTGD}. Here, we set the iteration times limitation to 10000,  surpassing which we think the algorithm failed. In task 4, we do RRT method for 10 times but none of them succeed, while RRT-GD could always succeed.
\item Within our experiments, RRT-GD could succeed as long as RRT method succeed. This is because there are usually not so many obstacles in the working space, and each obstacle is usually small enough (no more than 0.1$s$ in radius), while the radius of sample space is set to 0.5$m$, that is big enough to do common works with obstacle-avoiding.
\item Since RRT-GD uses less iteration times, so the planned path gived by RRT-GD seems to be better, i.e., less zig-zag on the path.
\item Multi-steps extending strategy shows in Fig. \ref{fig_multiExtend} works on well with RRT-GD since the extending directions is always goal-direction, so that it can speed up the process to reach goal.
\end{itemize}

Note that we return the program immediately if it finds the planned path from initial point to goal point when doing the tasks in Table \ref{table_RRTGD}. Of course, we could change it to get the best one as output in a certain iteration times. When doing these way, says iteration times limitation to 10000, RRT-GD can always get more paths out than RRT method, ending up with better planning path.

\section{CONCLUSIONS}

In this paper, we introduce a new method in obstacle-avoiding path planning, with RRT-GD method doing obstacle-avoiding, Newton-Raphson doing inverse kinematics, and quintic polynomial doing path smoothing. With RRT-GD, we can accomplish daily works faster and more efficient, usually 10$\sim$100 times faster than the usual RRT method because of its goal-directionality property. Note that when the sample space of RRT-GD is not full of the whole working space, RRT-GD may not give a right planning path as RRT in theory, i.e., it is not a universal relevance method. However, RRT-GD works well in practice, as we can see in the exprements, for that in our common working space, there are usually not so many obstacles and the size of each obstacle are usually small enough for RRT-GD to work on well. In the future, we will make improvements on the shortcomings of RRT-GD without varifying the sample space.

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{thebibliography}{99}

\bibitem{c1} Rapidly-Exploring Random Trees: Progress and Prospects, SM Lavalle, JJ Kuffner, Algorithmic \& Computational Robotics New Directions, 2000:293--308.
\bibitem{c2} RRT-connect: An efficient approach to single-query path planning, JJ Kuffner, SM Lavalle, Proc IEEE Intl Conf on Robotics \& Automation, 2000, 2:995 - 1001.
\bibitem{c3} Research on Kinematics and Obstacle Avoidance Path Planning for Redundant Manipulator, Yin Bin, Shi Shicai, Master Thesis, Harbin Institute of Technology, 2014. Classified Index:TP242.2, U.D.C:681.5.	
\bibitem{c4} Kinect-based Service Robot for Desktop Cleaning, Zheng Han, Meng Gao, ShiJiaZhuang Tiedao University, Master Thesis, 2013.
\bibitem{c5} Planning Method Considering the Kinetic Characteristics of the End Effector of a Redundant Manipulator, Wenbing Huang, Fuchun Sun, Huaping Liu, Qinghua Daxue Xuebao/journal of Tsinghua University, 2014,54(12):1544-1548.
\bibitem{c6} An Optimization Method for Inverse Kinematics of a 7-DOF Redundant Manipulator, Wenbin Yan, Lei Sun, Control Conference, 2015.
\bibitem{c7} Algorithm Based on Analytical Method and Genetic Algorithm for Inverse Kinematics of Redundant Manipulator, Yun Dong, Tao Yang, Wen Li, Computer Simulation, 2012.
\bibitem{c8} Trajectory Planning for a Robotic Ping-pong Player, Guowei Zhang, Bin Li, Huaibing Zhen, Haili Gong, Cong Wang, Chinese Journal of Scientific Instrument, Vol.32 No.6, Jun 2011.
\bibitem{c9} A Subdivision Algorithm in Configuration for Findpath with Rotation, Rodney A. Brooks, Tomas Lozano-Perez, Systems Man \& Cybemetics IEEE Transactions on, 1985, SMC-15(2):244-233.
\bibitem{c10} New Heuristic Algorithms for Efficient Hierarchical Path Planning, David Zhu and Jean-Claude Latombe, IEEE Transactions on Robotics \& Automation, 1991.7(1):9-20.
\bibitem{c11} A Methodology for Intelligent Path Planning, Suman Chakravorty, John L. Junkins, Proceedings of the 2005 IEEE International Symposium on Mediterrean Conference on Control and Automation, 10.1109/.2005.1467081, 13 March 2006.

\end{thebibliography}




\end{document}
